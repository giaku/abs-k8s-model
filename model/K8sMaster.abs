module K8sMaster;

export *;

import * from ABS.DC;
import * from K8sService;
import * from K8sUtil;
import * from ABS.Scheduler;

data NodeType = NodeType(String typeName, Map<String,Int> podsNumber)

//
// MASTER
//
interface Master{
  Bool deployService(Service s);

  List<NodeState> getNodesStates();

  List<Pair<String,ConsumptionMap>> getNodesMap();

  Bool createNodes(Int nNodes, Rat cpu, Rat memory, Rat baseSystemLoad, Map<String,Int> podsMap);

  Unit setSchedulerRulesMap(Map<String,List<Int>> rulesMap);
}
class MasterObject(CloudProvider cp, Rat timeUnitSize, Int loadPeriod, Int resourceCycle, Int costGranularity) implements Master{
  NodeScheduler scheduler;

  {
    scheduler = new NodeSchedulerObject(cp,loadPeriod,resourceCycle);
  }

  Bool deployService(Service s){
    await s!deploy(scheduler);
    return True;
  }

  List<NodeState> getNodesStates(){
    List<NodeState> list = await scheduler!getNodeStates();
    return list;
  }

  List<Pair<String,ConsumptionMap>> getNodesMap(){
    List<Pair<String,ConsumptionMap>> result = list[];
    List<Node> nList = await scheduler!getNodes();

    foreach (n in nList){
      NodeResourcesMonitor nMonitor = await n!getMonitor();
      String nodeName = await n!getName();
      ConsumptionMap map = await nMonitor!getConsumptionMap();

      result = appendright(result,Pair(nodeName,map));
    }

    return result;
  }

  Bool createNodes(Int nNodes, Rat cpu, Rat memory, Rat baseSystemLoad){
    await this.scheduler!createNodes(nNodes, cpu, memory, timeUnitSize, baseSystemLoad, costGranularity);
    return True;
  }

  Unit setSchedulerRulesMap(Map<String,List<Int>> rulesMap){
    await this.scheduler!setRulesMap(rulesMap);
  }
}

//
// NODE
//
interface Node{
  String getName();
  NodeResourcesMonitor getMonitor();
  //Use Node cpu, equivalent to [Cost: amount] skip;
  Unit consumeCpu(Rat amount,Pod p);

  Rat allocateMemory(Rat amount);
  Rat releaseMemory(Rat amount);

  Unit addPod(Pod p, ResourcesMonitor rm, String serviceName);
  Unit removePod(Pod p, ResourcesMonitor rm);

  List<Pod> getPods();

  Rat getRequestedCpu();
  Rat getAvailableCpu();

  Unit processRequest(NodeRequest request);
}
[Scheduler: node_reset_resources_scheduler(queue)] class NodeObject(Int id, Rat cpu, Rat memory, Rat timeUnitSize, Int cycle,
                                                                    Rat baseSystemCpuLoad, NodeResourcesMonitor monitor,
                                                                    Int costGranularity, Map<String,Int> podsMap,
                                                                    MasterLoadbalancer mlb, Map<Service,Map<Int,Rat>> calibrationMaps) implements Node{
  List<ResourcesMonitor> pMonitors = list[];
  List<Pod> pods = list[];
  String name = "";
  Bool refreshed = False;
  Bool memoryLock = False;
  Bool computing = False;
  Bool sysLoadInterleaving = False; // to interleave pods and system consumptions on the node

  Rat availableCpu = 0;
  Rat availableMemory = 0;
  Rat systemCpuLoad = 0;

  Rat requestedCpu = 0;

  Int remainingSysLoadSteps = 0;

  // fixed nodes calibration features
  List<NodeRequest> nodeReqsQueue = list[];

  {
    this.name = ("Node-" + toString(id));
    availableCpu = cpu;
    availableMemory = memory;
    println("TYPE:" + "node_creation" + " " + "TU:" + toString(now()) + " " + "NODE:" + this.name + " " + "CPU_CAPACITY:" + toString(cpu)
            + " " + "MEMORY_CAPACITY:" + toString(memory));
    systemCpuLoad = baseSystemCpuLoad;
    remainingSysLoadSteps = costGranularity;
    this!resetResources();
    this!consumeSystemLoad();
    this!consumeSystemCpu();
  }

  String getName(){
    return this.name;
  }

  List<Pod> getPods(){
    return this.pods;
  }

  NodeResourcesMonitor getMonitor(){
    return this.monitor;
  }

  // Sets the consumptions on the monitor and reset the availableCpu to the full value.
  // this method is the last method called by the scheduler every time unit.
  Unit resetResources(){

    monitor!setConsumedCpu(cpu - availableCpu);
    monitor!setConsumedMemory(memory - availableMemory);

    availableCpu = cpu;
    systemCpuLoad = baseSystemCpuLoad;
    remainingSysLoadSteps = costGranularity;

    await duration(cycle,cycle);

    this!resetResources();
  }

  // flush the list of the node request computing the total costs for its services
  // this method is executed once every time unit, after all the incoming requests for the time unit are in the list
  Unit convertRps(){
    Map<String,Int> serviceConsumptions = map(); // map to store the total consumption

    for (nodeReq in nodeReqsQueue){ // cycle through the node requests in the queue
      
    }

  }

  // consumes remaining system load, if there, after all pod consumptions in the time unit
  Unit consumeSystemLoad(){
    await duration(cycle/2,cycle/2);

    availableCpu = availableCpu - systemCpuLoad;
    //println("{TIME " + toString(timeValue(now())) + "} " + "[NODE " + toString(id) + "]" + "SYSTEM consumed: " + toString(systemCpuLoad) + " SYSTEM DISCHARGE");
    systemCpuLoad = 0;

    await duration(cycle/2,cycle/2);

    this!consumeSystemLoad();
  }

  // consumes part of the system load
  Unit consumeSystemCpu(){
    await sysLoadInterleaving;
    await (remainingSysLoadSteps > 0);

    Rat toConsume = systemCpuLoad / remainingSysLoadSteps;

    availableCpu = availableCpu - toConsume;
    systemCpuLoad = systemCpuLoad - toConsume;

    remainingSysLoadSteps = remainingSysLoadSteps - 1;
    sysLoadInterleaving = False;

    this!consumeSystemCpu();
  }

  Unit consumeCpu(Rat amount,Pod p){
    Bool done = False;
    Rat servAvailCpu = 0;

    while (!done){
      await (availableCpu - systemCpuLoad) > 0;
      servAvailCpu = availableCpu - systemCpuLoad;

      if (servAvailCpu >= amount){
        availableCpu = availableCpu - amount;

        sysLoadInterleaving = True;
        done = True;
      } else {
        amount = amount - servAvailCpu;
        availableCpu = availableCpu - servAvailCpu;
        p!setBlocked();
        await (availableCpu - systemCpuLoad) > 0;
      }
    }
  }

  Rat allocateMemory(Rat amount){
    Rat givenMemory = 0;
    await !this.memoryLock;
    this.memoryLock = True;

    if (availableMemory >= amount){
      availableMemory = availableMemory - amount;
      givenMemory = amount;
    }

    this.memoryLock = False;

    return givenMemory;

  }

  Rat releaseMemory(Rat amount){
    Rat releasedMemory = 0;
    await !this.memoryLock;

    this.memoryLock = True;
    availableMemory = availableMemory + amount;
    this.memoryLock = False;

    releasedMemory = amount;

    return releasedMemory;
  }

  Unit addPod(Pod p, ResourcesMonitor rm, String serviceName){
    Rat reqCpu = await rm!getCpuRequest();
    this.pMonitors = appendright(this.pMonitors,rm);
    this.pods = appendright(this.pods,p);

    this.requestedCpu = this.requestedCpu + reqCpu;
    monitor!setRequestedCpu(this.requestedCpu);

    // update the podsMap
    nPods = lookupDefault(podsMap,serviceName,-1);
    if (nPods == -1){
      this.podsMap = put(this.podsMap,serviceName,1);
    } else {
      this.podsMap = put(this.podsMap,serviceName,nPods + 1);
    }
    await mlb!updateNodeMap(this,this.podsMap);
  }

  Unit removePod(Pod p, ResourcesMonitor rm, String serviceName){
    Rat reqCpu = await rm!getCpuRequest();
    this.pMonitors = without(this.pMonitors,rm);
    this.pods = without(this.pods,p);

    this.requestedCpu = this.requestedCpu - reqCpu;
    monitor!setRequestedCpu(this.requestedCpu);

    // update the podsMap
    nPods = lookupDefault(podsMap,serviceName,-1);
    if (nPods == -1 || nPods == 0){
      println("===== ===== ERROR: REMOVING A POD FROM AN EMPTY NODE ===== =====");
      throw Exception;
    } else {
      this.podsMap = put(this.podsMap,serviceName,nPods - 1);
    }
    await mlb!updateNodeMap(this,this.podsMap);
  }

  List<ResourcesMonitor> getPMonitors(){
    return this.pMonitors;
  }

  Rat getRequestedCpu(){
    return this.requestedCpu;
  }

  Rat getAvailableCpu(){
    return this.cpu - this.requestedCpu;
  }

  Unit processRequest(NodeRequest request){

  }

}

//
// NODE BALANCER
//
interface NodeScheduler{
  //create nNodes with given cpu and memory amounts.
  Bool createNodes(Int nNodes, Rat cpu, Rat memory, Rat timeUnitSize, Rat baseSysConsumption, Int costGranularity);

  List<NodeState> getNodeStates();
  List<Node> getNodes();

  Node deployPod(Pod p,ResourcesMonitor rm);

  Unit setRulesMap(Map<String,List<Int>> rulesMap);
}

//loadPeriod: period to consider to select the less loaded node
class NodeSchedulerObject(CloudProvider cloud, Int loadPeriod, Int resourceCycle) implements NodeScheduler{
  // map of id:node
  Map<Int,Node> nodesMap = map[];
  Map<String,List<Int>> rulesMap = map[];
  // static list of all the nodes
  List<Node> nodes = list[];
  // list used to schedule new pods, can change order
  List<Node> activeNodes = list[];
  Int nextID = 1;

  // pod deploy lock
  Bool deploying = False;

  Bool createNodes(Int nNodes, Rat cpu, Rat memory, Rat timeUnitSize, Rat baseSysConsumption, Int costGranularity){
    Int ctr = 0;
    while (ctr < nNodes) {
      NodeResourcesMonitor monitor = new NodeResourcesMonitorObject(resourceCycle,cpu,memory);
      Node node = new NodeObject(nextID, cpu, memory, timeUnitSize, resourceCycle, baseSysConsumption, monitor, costGranularity);
      await monitor!setNode(node);
      nodes = appendright(nodes,node);
      activeNodes = appendright(activeNodes,node);
      nodesMap = insert(nodesMap,Pair(nextID,node));

      this.nextID = nextID + 1;
      ctr = ctr + 1;
    }
    println("[Time: "+toString(timeValue(now()))+"] *********** CREATED "+toString(nNodes)+" NODES [CPU: " + toString(cpu) + " - " + "MEMORY: " + toString(memory) + " ]");
    return True;
  }

  //returns the node with more not requested cpu available
  Node deployPod(Pod p, ResourcesMonitor rm){
    Bool deployed = False;
    Rat requestedCpu = await rm!getCpuRequest();
    String serviceName = await rm!getServiceName();
    Node result = null;
    List<Node> nodesToCheck = list[];

    List<Int> nodeIds = lookupDefault(rulesMap,serviceName,list[]);

    if (!isEmpty(nodeIds)){
      Node selected = lookupDefault(nodesMap,head(nodeIds),null);
      if (selected != null){
        nodesToCheck = list[selected];
        rulesMap = put(rulesMap,serviceName,cycleIntList(nodeIds)); // put the first node at the bottom of the list of the rule
      }
    }

    if (isEmpty(nodesToCheck)){ // standard behavior
      await (!isEmpty(activeNodes));
      nodesToCheck = activeNodes;
    }

    while (!deployed){
      await !deploying;
      this.deploying = True;
      Rat maxCpu = -1;

      foreach ( n in nodesToCheck){
        Rat cpu = await n!getAvailableCpu();
        if (cpu > maxCpu){
          maxCpu = cpu;
          result = n;
        }
      }

      if (maxCpu >= requestedCpu){
        await result!addPod(p,rm,serviceName);
        this.deploying = False;
        deployed = True;
      }else{
        this.deploying = False;
        await duration(1,1);
      }
    }
    return result;
  }

  List<NodeState> getNodeStates(){
    List<NodeState> list = list[];

    foreach (node in nodes){
      NodeResourcesMonitor monitor = await node!getMonitor();
      NodeState ns = await monitor!getNodeState();
      list = appendright(list,ns);
    }

    return list;
  }

  List<Node> getNodes(){
    return this.nodes;
  }

  Unit setRulesMap(Map<String,List<Int>> rulesMap){
    this.rulesMap = rulesMap;
  }
}

interface MasterLoadbalancer(){
  Unit balanceClientRequest(ClientRequest request);

  Unit addNode(Node n, Map<String,Int> podsMap);

  Unit updateNodeMap(Node node, Map<String,Int> podsMap);
}
class MasterLoadbalancerObject() implements MasterLoadbalancer{
  List<Node> activeNodes; // currently active nodes in the system
  Map<Node,Map<String,Int>> activeNodesMaps; // map contating the maps that indicates how many pods of a chosen service are deployed on the node
                                             // i.e. node1 -> [activeNodesMaps] = node1PodsMap; "service1" -> [node1PodsMap] = number of pods of service1 deployed on node1
  Map<String,Map<Node,Int>> perServicePodsNumber; // service based map, better for balancing



  Unit balanceClientRequest(ClientRequest request){
      WorkflowData wfd = wf(request);
      List<String> services = services(wfd);

      foreach (service in services){ // cycle through services of the workflow and balance the rps with a round-robin policy among the pods
        Map<Node,Int> servicePodMap = lookup(perServicePodsNumber,service);
        List<Pair<Node,Int>> quotas = generateSubrequestsSizes(rps(request),servicePodMap);

        foreach (quota in quotas){ // generate and forward the sub-requests
          Node node = fst(quota);
          Int size = snd(quota);

          NodeRequest nodeReq = NodeRequest(service,wfName(wfd),size); // create the node request (service,wf,rps) and sends it to the node
          node!processRequest(nodeReq); // send the request to the node
        }
      }
  }

  // takes a size and a podMap of a service and computes the number of request for every node, the policy is round-robin
  // between the pods.
  // the remaining K requests (K < Total number of pods for the service) are just given to the first K pods. (not balancing between the nodes)
  List<Pair<Node,Int>> generateSubrequestsSizes(Int rSize, Map<Node,Int> podsMap){
    List<Pair<Node,Int>> result = list();
    Int totalPods = foldr(+)(values(podsMap), 0);

    rPerPod = truncate(rSize / totalPods);
    remainingSize = rSize % totalPods;

    foreach (node in keys(podsMap)){
      Int nodePods = lookup(podsMap,node);
      Int subReqSize = rPerPod * nodePods;

      if (remainingSize >= nodePods){
        remainingSize = remainingSize - nodePods;
        subReqSize = subReqSize + nodePods;
      } else if (remainingSize > 0){
        subReqSize = subReqSize + remainingSize;
        remainingSize = 0;
      }

      result = appendright(result,pair(node,subReqSize));
    }

    return result;
  }

  Unit updateNodeMap(Node node, Map<String,Int> podsMap){
    this.activeNodesMaps = put(this.activeNodesMaps,node,podsMap);
    this.updatePerServicePods(node,podsMap);
  }

  // updates the number of pods in the service based map
  Unit updatePerServicePods(Node node, Map<String,Int> map){
    List<String> services = list(keys(map));

    foreach (service in services){ // for every service of the updated node:
      podMap = lookupDefault(perServicePodsNumber,service,map()); // take the map of that service
      podsNumber = lookup(map,service); // read the updated number of pods for that node
      podMap = put(podMap,node,podsNumber); // udpate the node entry in the service map

      perServicePodsNumber = put(perServicePodsNumber,service,podMap); // update the service entry in the perService map
    }
  }
}
